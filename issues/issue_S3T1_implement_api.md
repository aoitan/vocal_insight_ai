---
title: "[feat]: APIサーバー (FastAPI) の実装"
labels: "feature, api"
assignees: "@[担当者]"
---

## 概要

`vocal_insight_ai` コアライブラリとLLMゲートウェイを利用するWeb APIサーバーをFastAPIで実装します。これにより、WebUIや他のサービスから音声分析機能にアクセスできるようになります。

## 目的

- 音声分析機能のWebサービス化。
- 対話的な分析セッションをサポートするAPIエンドポイントの提供。
- LLM連携機能の提供。

## 詳細

- `/analyze_new` や `/chat_continue` など、WebUIからのリクエストを受け付けるためのAPIエンドポイントを設計・実装する。
- `LiteLLM` を利用したLLMゲートウェイ機能を実装し、LLMとの通信を抽象化する。
- リクエストに応じて、コアライブラリの分析関数とLLMゲートウェイを呼び出し、結果をJSON形式で返す。
- 対話履歴（セッション）を管理するロジックを実装する。

### 関連するファイル/モジュール

- `vocal_insight_api.py` (新規作成)

### 依存関係

- #issue_S1T2_define_core_interface.md (外部から利用するための関数インターフェース（入力・出力）を定義する)

## 完了の定義 (Definition of Done)

- [ ] 音声ファイルを受け取り、分析結果を返すAPIエンドポイントが動作すること。
- [ ] LLMとの連携が正しく行われ、分析結果が返されること。
- [ ] 対話セッション管理が機能すること。
- [ ] APIドキュメント（Swagger UIなど）が自動生成され、アクセス可能であること。
- [ ] コードレビューが完了していること。

## 備考

このIssueは、開発計画書の「ステップ3：Webアプリケーションの開発」のタスクです。
